{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial variables \n",
    "path_of_data = \"../FSRDset/*.csv\"\n",
    "path_of_output = \"../FirstPreProcess/\"\n",
    "\n",
    "sample_size_average = 30 # this value indicates the number of rows we will go over to build the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that will go over the different excel files and compute, for each file, the average of the different values on the scale of the sample size\n",
    "\n",
    "def average_over_sample_size(input_path, output_path, sample_size):\n",
    "    for fname in glob.glob(input_path): \n",
    "        with open(fname, 'r') as infh:\n",
    "            next(infh)\n",
    "            reader = csv.reader(infh, delimiter=\";\")\n",
    "\n",
    "            output = open(output_path + fname[10:], \"w+\")\n",
    "\n",
    "            # list of values to be taken from the csv files\n",
    "            timestamp_list = []\n",
    "            cpu_usage_list = []\n",
    "            mem_usage_percent_list = []\n",
    "            disk_read_list = []\n",
    "            disk_write_list = []\n",
    "            net_in_list = []\n",
    "            net_out_list = []\n",
    "\n",
    "            counter = 0\n",
    "            for row in reader:\n",
    "                timestamp = int(row[0])\n",
    "                cpu_usage = float(row[4])\n",
    "                mem_capacity = float(row[5])\n",
    "                mem_usage = float(row[6])\n",
    "                disk_read = float(row[7])\n",
    "                disk_write = float(row[8])\n",
    "                net_in = float(row[9])\n",
    "                net_out = float(row[10])\n",
    "\n",
    "                timestamp_list.append(timestamp)\n",
    "                cpu_usage_list.append(cpu_usage)\n",
    "\n",
    "                if (mem_capacity != 0):\n",
    "                    mem_usage_percent_list.append((mem_usage/mem_capacity)*100.0)\n",
    "                else :\n",
    "                    mem_usage_percent_list.append(0.0)\n",
    "                \n",
    "                disk_read_list.append(disk_read)\n",
    "                disk_write_list.append(disk_write)\n",
    "                net_in_list.append(net_in)\n",
    "                net_out_list.append(net_out)\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "\n",
    "                if counter >= sample_size:\n",
    "                    # Get the averages\n",
    "                    timestamp_avg = sum(timestamp_list)/len(timestamp_list)\n",
    "                    cpu_avg = sum(cpu_usage_list)/len(cpu_usage_list)\n",
    "                    mem_avg = sum(mem_usage_percent_list)/len(mem_usage_percent_list)\n",
    "                    disk_read_avg = sum(disk_read_list)/len(disk_read_list)\n",
    "                    disk_write_avg = sum(disk_write_list)/len(disk_write_list)\n",
    "                    net_in_avg = sum(net_in_list)/len(net_in_list)\n",
    "                    net_out_avg = sum(net_out_list)/len(net_out_list)\n",
    "\n",
    "                    class_num = -1\n",
    "\n",
    "                    if cpu_avg < 5.0:\n",
    "                        class_num = 0\n",
    "                    elif cpu_avg < 10.0:\n",
    "                        class_num = 1\n",
    "                    elif cpu_avg < 15.0:\n",
    "                        class_num = 2\n",
    "                    elif cpu_avg < 20.0:\n",
    "                        class_num = 3\n",
    "                    elif cpu_avg < 25.0:\n",
    "                        class_num = 4\n",
    "                    elif cpu_avg < 30.0:\n",
    "                        class_num = 5\n",
    "                    elif cpu_avg < 35.0:\n",
    "                        class_num = 6\n",
    "                    elif cpu_avg < 40.0:\n",
    "                        class_num = 7\n",
    "                    elif cpu_avg < 45.0:\n",
    "                        class_num = 8\n",
    "                    elif cpu_avg < 50.0:\n",
    "                        class_num = 9\n",
    "                    elif cpu_avg < 55.0:\n",
    "                        class_num = 10\n",
    "                    elif cpu_avg < 60.0:\n",
    "                        class_num = 11\n",
    "                    elif cpu_avg < 65.0:\n",
    "                        class_num = 12\n",
    "                    elif cpu_avg < 70.0:\n",
    "                        class_num = 13\n",
    "                    elif cpu_avg < 75.0:\n",
    "                        class_num = 14\n",
    "                    elif cpu_avg < 80.0:\n",
    "                        class_num = 15\n",
    "                    elif cpu_avg < 85.0:\n",
    "                        class_num = 16\n",
    "                    elif cpu_avg < 90.0:\n",
    "                        class_num = 17\n",
    "                    elif cpu_avg < 95.0:\n",
    "                        class_num = 18\n",
    "                    else:\n",
    "                        class_num = 19\n",
    "\n",
    "                    counter = 0\n",
    "                    timestamp_list = []\n",
    "                    cpu_usage_list = []\n",
    "                    mem_usage_percent_list = []\n",
    "                    disk_read_list = []\n",
    "                    disk_write_list = []\n",
    "                    net_in_list = []\n",
    "                    net_out_list = []\n",
    "\n",
    "                    output.write(str(timestamp_avg) + ';' + str(cpu_avg) + ';' + str(mem_avg) + ';' + str(disk_read_avg) + ';' + str(disk_write_avg) + ';' + str(net_in_avg) + ';' + str(net_out_avg) + ';' + str(class_num) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_over_sample_size(path_of_data, path_of_output, sample_size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a function that will prepare the data for training\n",
    "# the goal here is to build a ML model based on time series data\n",
    "# so the data feeded as input to the model should be arranged in such a form : \n",
    "#   - the model basis itself on the past, to predict the future\n",
    "#   - that means, he takes values in time, over a period of time (that I should define)\n",
    "#     and then predicts something in the future\n",
    "#   - let's say I want to predict the number of bananas eaten a day by a monkey, based\n",
    "#     on the number of bananas he ate the past week, that is how my data should look like : \n",
    "# Input to the model : 6 bananas on Monday, 4 on Tuesday, 5 on Wednesday, 6 on Th, 7 on F, 8 on Sat, 5 on Sun -> Now predict how many for next monday\n",
    "# now let's do that but for the VMS that we got\n",
    "# we want to predict CPU usage, based on previous CPU usage, and we also have other metrics that we might use later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_preprocess_path = \"../FirstPreProcess/*.csv\"\n",
    "second_preprocess_path = \"../SecondPreProcess/\"\n",
    "\n",
    "features_multiplier = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(input_path, output_path,  features_multiplier):\n",
    "\n",
    "    for fname in glob.glob(input_path):\n",
    "        with open(fname, 'r') as infh:\n",
    "            reader = csv.reader(infh, delimiter=';')\n",
    "\n",
    "            output = open(output_path + fname[19:], \"w+\")\n",
    "\n",
    "            csv_file_list = []\n",
    "\n",
    "            for row in reader:\n",
    "                timestamp_avg = float(row[0])\n",
    "                cpu_avg = float(row[1])\n",
    "                mem_avg = float(row[2])\n",
    "                disk_read_avg = float(row[3])\n",
    "                disk_write_avg = float(row[4])\n",
    "                net_in_avg = float(row[5])\n",
    "                net_out_avg = float(row[6])\n",
    "                class_num = float(row[7])\n",
    "\n",
    "                entry_list = [timestamp_avg, cpu_avg, mem_avg, disk_read_avg, disk_write_avg, net_in_avg, net_out_avg, class_num]\n",
    "                csv_file_list.append(entry_list)\n",
    "\n",
    "\n",
    "            i = 0\n",
    "            while i < len(csv_file_list) - features_multiplier:\n",
    "                upperbound = i + features_multiplier\n",
    "\n",
    "                j = i\n",
    "                while j < upperbound:\n",
    "                    output.write(str(csv_file_list[j][0]) + ';' + str(csv_file_list[j][1]) + ';' + str(csv_file_list[j][2]) + ';' + str(csv_file_list[j][3]) + ';' + str(\n",
    "                        csv_file_list[j][4]) + ';' + str(csv_file_list[j][5]) + ';' + str(csv_file_list[j][6]) + ';')\n",
    "                    j += 1\n",
    "                output.write(str(csv_file_list[j][7]) + '\\n')\n",
    "\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_data(first_preprocess_path, second_preprocess_path, features_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbf9d42aedbc90768b4389b53ce2f5e905e9c8eae5bc6beefed2c29eab5b146b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
